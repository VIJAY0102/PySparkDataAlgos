{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page_No: 50 - 61\n",
    "# Top N List in each Partition - Unique Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Creating a RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat1,12', 'cat2,13', 'cat3,14']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filePath = \"./DataSet/top10data.csv\"\n",
    "tTen = sc.textFile(filePath)\n",
    "tTen.take(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Creating PairRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsetTen(data):\n",
    "    records = data.split(',')\n",
    "    return (records[0], int(records[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tPRDD = tTen.map(parsetTen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cat1', 12), ('cat2', 13), ('cat3', 14)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat1', 12),\n",
       "  ('cat2', 13),\n",
       "  ('cat3', 14),\n",
       "  ('cat4', 15),\n",
       "  ('cat5', 10),\n",
       "  ('cat100', 100),\n",
       "  ('cat200', 200),\n",
       "  ('cat300', 300),\n",
       "  ('cat1001', 1001)],\n",
       " [('cat67', 67),\n",
       "  ('cat22', 22),\n",
       "  ('cat23', 23),\n",
       "  ('cat1000', 1000),\n",
       "  ('cat2000', 2000),\n",
       "  ('cat400', 400),\n",
       "  ('cat500', 500)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.glom().take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat1', 12),\n",
       "  ('cat2', 13),\n",
       "  ('cat3', 14),\n",
       "  ('cat4', 15),\n",
       "  ('cat5', 10),\n",
       "  ('cat100', 100),\n",
       "  ('cat200', 200),\n",
       "  ('cat300', 300),\n",
       "  ('cat1001', 1001)],\n",
       " [('cat67', 67),\n",
       "  ('cat22', 22),\n",
       "  ('cat23', 23),\n",
       "  ('cat1000', 1000),\n",
       "  ('cat2000', 2000),\n",
       "  ('cat400', 400),\n",
       "  ('cat500', 500)]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat1', 12),\n",
       "  ('cat100', 100),\n",
       "  ('cat1000', 1000),\n",
       "  ('cat1001', 1001),\n",
       "  ('cat2', 13),\n",
       "  ('cat200', 200),\n",
       "  ('cat2000', 2000),\n",
       "  ('cat22', 22),\n",
       "  ('cat23', 23)],\n",
       " [('cat3', 14),\n",
       "  ('cat300', 300),\n",
       "  ('cat4', 15),\n",
       "  ('cat400', 400),\n",
       "  ('cat5', 10),\n",
       "  ('cat500', 500),\n",
       "  ('cat67', 67)]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#By using sortByKey spark do it by selecting random and shuffle it \n",
    "tPRDD.sortByKey().glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Before MapPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat1', 12),\n",
       "  ('cat2', 13),\n",
       "  ('cat3', 14),\n",
       "  ('cat4', 15),\n",
       "  ('cat5', 10),\n",
       "  ('cat100', 100),\n",
       "  ('cat200', 200),\n",
       "  ('cat300', 300),\n",
       "  ('cat1001', 1001)],\n",
       " [('cat67', 67),\n",
       "  ('cat22', 22),\n",
       "  ('cat23', 23),\n",
       "  ('cat1000', 1000),\n",
       "  ('cat2000', 2000),\n",
       "  ('cat400', 400),\n",
       "  ('cat500', 500)]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### After MapPartitions \n",
    "#### 1: Finding Minimum and Maximum Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def partitionsFunc(data):\n",
    "#     '''\n",
    "#     type(data) = Python map()\n",
    "#     '''\n",
    "#     initialData = 0\n",
    "#     for iter1 in data:\n",
    "#         if initialData == 0:\n",
    "#             minD = iter1[1]\n",
    "#             minKv = iter1\n",
    "#             maxD = iter1[1]\n",
    "#             maxKv = iter1\n",
    "#             initialData = 1\n",
    "#         else:\n",
    "#             if iter1[1] > maxD:\n",
    "#                 maxD = iter1[1]\n",
    "#                 maxKv = iter1\n",
    "#             elif iter1[1] < minD:\n",
    "#                 minD = iter1[1]\n",
    "#                 minKv = iter1\n",
    "#     return (maxKv, minKv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partitionsFun(data):\n",
    "    '''\n",
    "    type(data) = Python map()\n",
    "    '''\n",
    "    dataList = list(data)\n",
    "    return (max(dataList, key=lambda x: x[1]), min(dataList, key=lambda x: x[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def partitionsFun(data):\n",
    "#     '''\n",
    "#     type(data) = Python map()\n",
    "#     '''\n",
    "#     dataList = list(sorted(data, key=lambda x: x[1]))\n",
    "#     return (dataList[0], dataList[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat1001', 1001), ('cat5', 10)], [('cat2000', 2000), ('cat22', 22)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.mapPartitions(partitionsFun).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2: Finding Top 5 List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNListAsc(data):\n",
    "    dataLRDD = sorted(list(data), key=lambda x: x[1])\n",
    "    return dataLRDD[:5]\n",
    "\n",
    "def topNListDesc(data):\n",
    "    dataLRDD = sorted(list(data), key=lambda x: x[1], reverse=True)\n",
    "    return dataLRDD[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat5', 10), ('cat1', 12), ('cat2', 13), ('cat3', 14), ('cat4', 15)],\n",
       " [('cat22', 22),\n",
       "  ('cat23', 23),\n",
       "  ('cat67', 67),\n",
       "  ('cat400', 400),\n",
       "  ('cat500', 500)]]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.mapPartitions(topNListAsc).glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat1001', 1001),\n",
       "  ('cat300', 300),\n",
       "  ('cat200', 200),\n",
       "  ('cat100', 100),\n",
       "  ('cat4', 15)],\n",
       " [('cat2000', 2000),\n",
       "  ('cat1000', 1000),\n",
       "  ('cat500', 500),\n",
       "  ('cat400', 400),\n",
       "  ('cat67', 67)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.mapPartitions(topNListDesc).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3: Finding Top N List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#need to see it in real environment Vj\n",
    "#Status - Not Tested.\n",
    "\n",
    "#The Broadcast class enables us to define globally shared data structures and then read them from any cluster node\n",
    "nValue = sc.broadcast(2)\n",
    "#it may be read from any cluster node within mappers, reducers, and transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def topNListAsc(data):\n",
    "    dataLRDD = sorted(list(data), key=lambda x: x[1])\n",
    "    return dataLRDD[:nValue.value]\n",
    "\n",
    "def topNListDesc(data):\n",
    "    dataLRDD = sorted(list(data), key=lambda x: x[1], reverse=True)\n",
    "    return dataLRDD[:nValue.value]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('cat5', 10), ('cat1', 12)], [('cat22', 22), ('cat23', 23)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tPRDD.mapPartitions(topNListAsc).glom().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mapPartitions Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lRDD = sc.parallelize([4, 3, 3, 1], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For getting the number of partitions\n",
    "lRDD.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For Getting the Partition\n",
    "* glom\n",
    "* foreachpartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[4, 3], [3, 1]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# glom() for seeing the Partitions as such\n",
    "lRDD.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refer the o/p in spark console\n",
    "def display(data):\n",
    "    print(list(data))\n",
    "lRDD.foreachPartition(display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sumOfPartitions(data):\n",
    "    yield sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 4]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lRDD.mapPartitions(sumOfPartitions).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
